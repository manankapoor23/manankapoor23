# Hi, I'm Manan Kapoor   

 **Sophomore Engineering Student (COE)**  
 Thapar Institute of Engineering & Technology, India  
 Aspiring **Software Developer** | **AI/ML Research Enthusiast** | **Web Dev Explorer**

I love building things that *actually work* â€” from ML pipelines and datasets for LLMs to clean web projects and creative media.  
Currently exploring the intersection of **Machine Learning, LLMs, and real-world systems**.

---

##  Roles & Experience  

**Research Intern** â€” Thapar Institute of Engineering & Technology *(2025â€“Present)*  
- Built end-to-end **data engineering pipelines** for Punjabi LLM fine-tuning  
- Processed **16.2M+ tokens (1.1M sentences)** with deduplication & noise filtering  
- Designed **training-ready JSONL benchmarks** for instruction tuning & evaluation  
- Worked with NLP, statistics, hypothesis testing, and reproducible research workflows  

**Media Intern** â€” Escape Media Tech *(Junâ€“Jul 2025)*  
- Created 15+ short-form videos with **100K+ total views**  
- Handled on-ground media coverage across 3+ cities  
- Delivered end-to-end content from raw footage â†’ platform-ready outputs  

**Clubs & Societies**  
- Core Member â€” **Echoes Club** (Creative Assistant) [2025]  
- Member â€” **Echoes Club** (Media & Content Team) [2024]  
- Core Member â€” **Saturnalia 2025** (Tech Team)  

 Photographer |  Videographer |  Creative Designer  

---

##  What Iâ€™m Currently Learning  

- **C++ & Data Structures / Algorithms**  
- **Machine Learning & Deep Learning**  
- **LLMs, Transformers, RAG & GenAI**  
- **Python for Data Science & Automation**  
- **SQL & Databases**  
- **Statistics & Hypothesis Testing**  
- **Photography & Cinematography**  
- Reducing my **Diet Coke dependency** (ongoing battle)

---
## ğŸ§  AI Systems & LLM Internals (Current Focus)

Iâ€™m exploring **how modern AI systems actually run under the hood** â€” not just how to call APIs.

My current focus is on **LLM inference, memory management, and production-scale design**, bridging **deep learning + systems engineering**.

### ğŸ” What Iâ€™m Studying
- Autoregressive decoding in transformer models  
- **Keyâ€“Value (KV) cache mechanics**  
- Inference-time memory behavior  
- Latency vs throughput tradeoffs  
- Why naÃ¯ve inference implementations break at scale  

I strongly believe **understanding inference is as important as training models**.

---

### ğŸ”¬ Recent Deep Dive: KV Cache (Hands-on)

I implemented and experimented with a **naive KV-cache** using open-source transformer models to understand real inference behavior.

**Key insights:**
- KV cache correctly avoids recomputing attention for past tokens  
- Naive KV cache **grows unbounded** in multi-turn conversations  
- In production:
  - Prompt & response lengths are unknown
  - Contiguous allocation becomes fragile
  - Memory fragmentation and waste increase over time
  - Decoder-side memory pressure continuously grows
- Framework-level KV caches abstract memory layout, limiting control  

 **Conclusion:** Naive KV caching is *correct*, but **not scalable**.

---

###  What Iâ€™m Exploring Next: Paged KV Cache

Iâ€™m now working on a **paged KV-cache design**, inspired by production inference engines, to understand:

- How fixed-size KV pages prevent fragmentation  
- Decoupling logical token order from physical memory  
- Prefix reuse: *compute once, reuse many times*  
- Reference counting & copy-on-write for safe sharing  
- How OS concepts (paging, virtual memory) apply directly to LLM inference  

> **KV cache enables reuse over time.  
> Paging enables reuse over space.**

---

### ğŸ›  Tech Stack (Systems + AI)
- Python  
- PyTorch  
- Hugging Face Transformers  
- Apple Silicon (CPU / MPS)  
- Inference debugging, profiling & benchmarking  
- API usage: **OpenAI SDK, Google APIs**, and modern ML tooling  

I prefer **correctness, clarity, and understanding** over chasing benchmarks.

---

###  What I Care About
- AI **systems**, not just AI models  
- How things **scale**, not just how they work once  
- Building mental models, not copying code  
- Treating CS fundamentals as **skills**, not subjects  

---

###  Philosophy
> *â€œUnderstanding how AI runs is as important as understanding how it learns.â€*

## ğŸ›  Tech Stack  

### Languages
<p align="center">
  <img src="https://skillicons.dev/icons?i=cpp,python,js,r,html,css,sql" />
</p>

### ML / AI
- Machine Learning, Deep Learning, Neural Networks  
- Transformers, LLMs, RAG, Instruction Tuning  
- NLP, Dataset Engineering, Model Evaluation  

### Libraries & Tools
- Pandas, NumPy, Scikit-learn, PyTorch, Matplotlib  
- LangChain, OpenAI SDK, NLTK  
- Git, GitHub, Docker, VS Code, Jupyter, RStudio  

### CS Fundamentals
- DSA, OOP, OS, DBMS, Computer Networks  
- Probability & Statistics  

---

## ğŸ§ª Featured Projects  

### ğŸ”¥ **Hestia â€” Fire Prediction & Analysis Model**
- End-to-end ML pipeline on environmental data  
- Feature analysis identified **temperature & RH** as key predictors  
- Focused on interpretability & early-warning insights  

### ğŸ§¾ **Punjabi Text Simplification Dataset (LLMs)**
- 16M+ token dataset built for supervised fine-tuning  
- Automated cleaning, deduplication & validation pipelines  
- Research-driven design based on peer-reviewed papers  

### ğŸ“Š **PunjabiSimplify-R**
- R-based framework to evaluate LLM text simplification  
- Used **paired t-tests**, descriptive statistics & readability metrics  

### ğŸ¨ **Art Style Predictor**
- AI model for classifying artwork styles  
- Planned extensions to artist & emotion prediction  

### ğŸ“¸ **Photography Portfolio**
- Experiments with light, framing, and visual storytelling  

---

## ğŸ“Š GitHub Stats  

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=manankapoor23&show_icons=true&theme=tokyonight" />
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=manankapoor23&theme=tokyonight" />
</p>

---

## ğŸŒ± Currently Working On  

- Improving **GitHub repos & documentation**  
- Exploring **open-source contributions & hackathons**  
- Deep diving into **LLMs & Generative AI**  
- Building projects that combine **ML + systems + real data**

---

## ğŸ¤ Connect With Me  

<p align="center">
  <a href="https://www.linkedin.com/in/manan-kapoor-8545002a0/">
    <img src="https://skillicons.dev/icons?i=linkedin" />
  </a>
  <a href="mailto:23.kapoormanan@gmail.com">
    <img src="https://skillicons.dev/icons?i=gmail" />
  </a>
  <a href="https://x.com/Manankap2311">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/x.svg" width="40" height="40"/>
  </a>
</p>

---

![snake gif](https://github.com/manankapoor23/manankapoor23/blob/output/github-snake-dark.svg)

